name: Run K6 Load Test on ECS

on:
  workflow_dispatch:
    inputs:
      app_folder:
        description: 'Application folder (e.g., app1, app2)'
        required: true
        default: 'app1'
      script_name:
        description: 'K6 script name (e.g., test1.js)'
        required: true
        default: 'test1.js'
      duration:
        description: 'Test duration (e.g., 30s, 5m)'
        required: false
        default: '1m'
      vus:
        description: 'Number of virtual users'
        required: false
        default: '10'
      version_suffix:
        description: 'Version suffix (e.g., -v2, leave empty for default)'
        required: false
        default: ''

env:
  AWS_REGION: us-east-1
  AWS_ACCOUNT_ID: 983610474809

jobs:
  run-k6-test:
    name: Execute K6 Load Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Set resource names with version suffix
        id: resources
        run: |
          SUFFIX="${{ github.event.inputs.version_suffix }}"
          echo "ecs-cluster=k6-cluster-${{ env.AWS_ACCOUNT_ID }}${SUFFIX}" >> $GITHUB_OUTPUT
          echo "task-definition=k6-task-${{ env.AWS_ACCOUNT_ID }}${SUFFIX}" >> $GITHUB_OUTPUT
          echo "s3-bucket=k6-artifacts-${{ env.AWS_ACCOUNT_ID }}${SUFFIX}" >> $GITHUB_OUTPUT
      
      - name: Generate unique run ID
        id: run-info
        run: |
          # Create globally unique ID combining date, time, run number, and run ID
          RUN_ID="$(date +%Y%m%d-%H%M%S)-${{ github.run_number }}-${{ github.run_id }}"
          echo "run-id=${RUN_ID}" >> $GITHUB_OUTPUT
          echo "Run ID: ${RUN_ID}"
          echo "::notice::ðŸ”‘ Run ID: ${RUN_ID}"
      
      - name: Upload test scripts to S3 (unique path)
        run: |
          # Use unique S3 path to avoid collisions between concurrent runs
          S3_RUN_PATH="runs/${{ steps.run-info.outputs.run-id }}"
          
          echo "Uploading to: s3://${{ steps.resources.outputs.s3-bucket }}/${S3_RUN_PATH}"
          
          # Upload scripts (required)
          if [ -d "${{ github.event.inputs.app_folder }}/scripts" ]; then
            aws s3 cp ${{ github.event.inputs.app_folder }}/scripts/ \
              s3://${{ steps.resources.outputs.s3-bucket }}/${S3_RUN_PATH}/scripts/ \
              --recursive
            echo "âœ“ Scripts uploaded"
          else
            echo "::error::Scripts directory not found: ${{ github.event.inputs.app_folder }}/scripts"
            exit 1
          fi
          
          # Upload data if exists (optional)
          if [ -d "${{ github.event.inputs.app_folder }}/data" ]; then
            aws s3 cp ${{ github.event.inputs.app_folder }}/data/ \
              s3://${{ steps.resources.outputs.s3-bucket }}/${S3_RUN_PATH}/data/ \
              --recursive
            echo "âœ“ Data uploaded"
          fi
          
          # Upload utilities if exists (optional)
          if [ -d "k6-custom-processor-utilities" ]; then
            aws s3 cp k6-custom-processor-utilities/ \
              s3://${{ steps.resources.outputs.s3-bucket }}/${S3_RUN_PATH}/utilities/ \
              --recursive
            echo "âœ“ Utilities uploaded"
          fi
          
          # Save for later steps
          echo "S3_RUN_PATH=${S3_RUN_PATH}" >> $GITHUB_ENV
          
          echo "::notice::ðŸ“¦ Test files uploaded to S3"
      
      - name: Get default VPC and subnets
        id: vpc-info
        run: |
          # Get default VPC
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=isDefault,Values=true" \
            --query 'Vpcs[0].VpcId' \
            --output text)
          echo "vpc-id=${VPC_ID}" >> $GITHUB_OUTPUT
          
          # Get subnets in default VPC
          SUBNETS=$(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=${VPC_ID}" \
            --query 'Subnets[].SubnetId' \
            --output text | tr '\t' ',')
          echo "subnet-ids=${SUBNETS}" >> $GITHUB_OUTPUT
          
          # Get default security group
          SG_ID=$(aws ec2 describe-security-groups \
            --filters "Name=vpc-id,Values=${VPC_ID}" "Name=group-name,Values=default" \
            --query 'SecurityGroups[0].GroupId' \
            --output text)
          echo "security-group-id=${SG_ID}" >> $GITHUB_OUTPUT
      
      - name: Get latest task definition
        id: task-def
        run: |
          TASK_DEF_ARN=$(aws ecs describe-task-definition \
            --task-definition ${{ steps.resources.outputs.task-definition }} \
            --query 'taskDefinition.taskDefinitionArn' \
            --output text)
          echo "task-def-arn=${TASK_DEF_ARN}" >> $GITHUB_OUTPUT
      
      - name: Run ECS Fargate task
        id: run-task
        run: |
          TASK_ARN=$(aws ecs run-task \
            --cluster ${{ steps.resources.outputs.ecs-cluster }} \
            --task-definition ${{ steps.task-def.outputs.task-def-arn }} \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={
              subnets=[${{ steps.vpc-info.outputs.subnet-ids }}],
              securityGroups=[${{ steps.vpc-info.outputs.security-group-id }}],
              assignPublicIp=ENABLED
            }" \
            --overrides '{
              "containerOverrides": [
                {
                  "name": "k6-runner",
                  "environment": [
                    {"name": "APP_FOLDER", "value": "${{ github.event.inputs.app_folder }}"},
                    {"name": "SCRIPT_NAME", "value": "${{ github.event.inputs.script_name }}"},
                    {"name": "S3_BUCKET", "value": "${{ steps.resources.outputs.s3-bucket }}"},
                    {"name": "S3_RUN_PATH", "value": "${{ env.S3_RUN_PATH }}"},
                    {"name": "AWS_REGION", "value": "${{ env.AWS_REGION }}"},
                    {"name": "RUN_ID", "value": "${{ steps.run-info.outputs.run-id }}"},
                    {"name": "K6_DURATION", "value": "${{ github.event.inputs.duration }}"},
                    {"name": "K6_VUS", "value": "${{ github.event.inputs.vus }}"}
                  ]
                }
              ]
            }' \
            --query 'tasks[0].taskArn' \
            --output text)
          
          echo "task-arn=${TASK_ARN}" >> $GITHUB_OUTPUT
          echo "ECS Task started: ${TASK_ARN}"
          echo "::notice::ðŸš€ ECS Task ARN: ${TASK_ARN}"
      
      - name: Wait for task to complete
        run: |
          echo "â³ Waiting for ECS task to complete..."
          echo "Task ARN: ${{ steps.run-task.outputs.task-arn }}"
          
          aws ecs wait tasks-stopped \
            --cluster ${{ steps.resources.outputs.ecs-cluster }} \
            --tasks ${{ steps.run-task.outputs.task-arn }}
          
          echo "âœ“ Task completed!"
      
      - name: Get task exit code
        id: task-result
        run: |
          EXIT_CODE=$(aws ecs describe-tasks \
            --cluster ${{ steps.resources.outputs.ecs-cluster }} \
            --tasks ${{ steps.run-task.outputs.task-arn }} \
            --query 'tasks[0].containers[0].exitCode' \
            --output text)
          
          echo "exit-code=${EXIT_CODE}" >> $GITHUB_OUTPUT
          echo "Task exit code: ${EXIT_CODE}"
          
          if [ "${EXIT_CODE}" != "0" ]; then
            echo "::error::âŒ K6 test failed with exit code ${EXIT_CODE}"
            exit 1
          else
            echo "::notice::âœ… K6 test passed!"
          fi
      
      - name: Clean up S3 test scripts (security)
        if: always()
        run: |
          # Delete uploaded scripts after task completes (security best practice)
          echo "ðŸ§¹ Cleaning up uploaded test scripts from S3..."
          aws s3 rm s3://${{ steps.resources.outputs.s3-bucket }}/${S3_RUN_PATH}/ --recursive
          echo "âœ“ Cleanup complete"
      
      - name: Generate results URLs
        if: always()
        run: |
          S3_RESULTS_URL="https://s3.console.aws.amazon.com/s3/buckets/${{ steps.resources.outputs.s3-bucket }}?prefix=results/${{ github.event.inputs.app_folder }}/${{ steps.run-info.outputs.run-id }}/&region=${{ env.AWS_REGION }}"
          LOG_URL="https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#logsV2:log-groups/log-group/\$252Fecs\$252Fk6-logs-${{ env.AWS_ACCOUNT_ID }}${{ github.event.inputs.version_suffix }}"
          
          echo "ðŸ“Š Test Results: ${S3_RESULTS_URL}"
          echo "ðŸ“ CloudWatch Logs: ${LOG_URL}"
          
          echo "::notice::ðŸ“Š Results: ${S3_RESULTS_URL}"
          echo "::notice::ðŸ“ Logs: ${LOG_URL}"

  download-results:
    name: Download and Archive Results
    runs-on: ubuntu-latest
    needs: run-k6-test
    if: always()
    
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Set resource names
        id: resources
        run: |
          SUFFIX="${{ github.event.inputs.version_suffix }}"
          echo "s3-bucket=k6-artifacts-${{ env.AWS_ACCOUNT_ID }}${SUFFIX}" >> $GITHUB_OUTPUT
      
      - name: Download results from S3
        run: |
          # Reconstruct the run ID (it's from the previous job)
          RUN_ID=$(aws s3 ls s3://${{ steps.resources.outputs.s3-bucket }}/results/${{ github.event.inputs.app_folder }}/ | sort | tail -1 | awk '{print $2}' | tr -d '/')
          
          echo "Downloading results for run: ${RUN_ID}"
          
          mkdir -p results
          aws s3 cp s3://${{ steps.resources.outputs.s3-bucket }}/results/${{ github.event.inputs.app_folder }}/${RUN_ID}/ results/ --recursive || true
          
          if [ -f "results/summary.json" ]; then
            echo "âœ“ Results downloaded successfully"
            echo "ðŸ“ˆ Test Summary:"
            cat results/summary.json | jq -r '.metrics | to_entries[] | "\(.key): \(.value)"' || cat results/summary.json
          fi
      
      - name: Upload results as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: k6-results-${{ github.event.inputs.app_folder }}-${{ github.run_number }}
          path: results/
          retention-days: 30
